{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liaisons-experiments - Framework Try-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liaisons_experiments.experiments.multi_experiment import MultiExperiment\n",
    "from tqdm.notebook import tqdm\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "llms = [\n",
    "    ChatOllama(\n",
    "        model=\"gemma:2b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"gemma:7b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"gemma2:9b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"gemma2:27b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"mistral:7b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"mixtral:8x7b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"phi3:3.8b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"phi3:14b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"llama3:8b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"llama3:70b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOllama(\n",
    "        model=\"qwen2:0.5b\",\n",
    "        base_url=\"http://ollama.workstation\"\n",
    "    ),\n",
    "    ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_OPENAI_API_KEY\"),\n",
    "    ),\n",
    "    ChatOpenAI(\n",
    "        model_name=\"gpt-4-turbo\",\n",
    "        openai_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_OPENAI_API_KEY\"),\n",
    "    ),\n",
    "    ChatOpenAI(\n",
    "        model_name=\"gpt-4o\",\n",
    "        openai_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_OPENAI_API_KEY\"),\n",
    "    ),\n",
    "    ChatAnthropic(\n",
    "        model='claude-3-haiku-20240307',\n",
    "        anthropic_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_ANTHROPIC_API_KEY\"),\n",
    "    ),\n",
    "    ChatAnthropic(\n",
    "        model='claude-3-sonnet-20240229',\n",
    "        anthropic_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_ANTHROPIC_API_KEY\"),\n",
    "    ),\n",
    "    ChatAnthropic(\n",
    "        model='claude-3-5-sonnet-20240620',\n",
    "        anthropic_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_ANTHROPIC_API_KEY\"),\n",
    "    ),\n",
    "    ChatAnthropic(\n",
    "        model='claude-3-opus-20240229',\n",
    "        anthropic_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_ANTHROPIC_API_KEY\"),\n",
    "    ),\n",
    "    GoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        google_api_key=os.environ.get(\"LIAISONS_EXPERIMENTS_GOOGLE_API_KEY\"),\n",
    "    )\n",
    "]\n",
    "\n",
    "exps = MultiExperiment(llms, output_dir=\"./.dev\", tqdm=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_ibm_few_shot_prompting(arg_1: str, arg_2: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Arg1: Even in the case of provocateurs, it can be an effective strategy to call their bluff, by offering them a chance to have a rational conversation. In this case, the failure to do so is their responsibility alone.\n",
    "Arg2: No-platforming hinders productive discourse.\n",
    "Relation: attack\n",
    "\n",
    "Arg1: A country used to receiving ODA may be perpetually bound to depend on handouts (pp. 197).\n",
    "Arg2: Government structures adapt to handle and distribute incoming ODA. As the funding from ODA is significant, countries have vested bureaucratic interest to remain bound to aid (pp. 197).\n",
    "Relation: support\n",
    "\n",
    "Arg1: Elections would limit the influence of lobbyists on the appointment of Supreme Court judges.\n",
    "Arg2: The more individuals take part in a decision, as would be the case in a popular vote compared to a vote in the Senate, the harder it is to sway the outcome.\n",
    "Relation: support\n",
    "\n",
    "Arg1: ChatGPT will reach AGI level before 2030.\n",
    "Arg2: To reach AGI it should be able to generate its own goals and intentions: where would it draw these from?\n",
    "Relation: attack\n",
    "\n",
    "Arg1: {arg_1}\n",
    "Arg2: {arg_2}\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "binary_results = exps.run_from_csv(\".dev/inputs/ibm_claim_stance_binary_sample.csv\", binary_ibm_few_shot_prompting, relation_dim=\"binary\")\n",
    "\n",
    "binary_results.f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ternary_ibm_few_shot_prompting(arg_1: str, arg_2: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Arg1: Even in the case of provocateurs, it can be an effective strategy to call their bluff, by offering them a chance to have a rational conversation. In this case, the failure to do so is their responsibility alone.\n",
    "Arg2: No-platforming hinders productive discourse.\n",
    "Relation: attack\n",
    "\n",
    "Arg1: ChatGPT will reach AGI level before 2030.\n",
    "Arg2: Government structures adapt to handle and distribute incoming ODA. As the funding from ODA is significant, countries have vested bureaucratic interest to remain bound to aid (pp. 197).\n",
    "Relation: unrelated\n",
    "\n",
    "Arg1: Elections would limit the influence of lobbyists on the appointment of Supreme Court judges.\n",
    "Arg2: The more individuals take part in a decision, as would be the case in a popular vote compared to a vote in the Senate, the harder it is to sway the outcome.\n",
    "Relation: support\n",
    "\n",
    "Arg1: A country used to receiving ODA may be perpetually bound to depend on handouts (pp. 197).\n",
    "Arg2: To reach AGI it should be able to generate its own goals and intentions: where would it draw these from?\n",
    "Relation: unrelated\n",
    "\n",
    "Arg1: {arg_1}\n",
    "Arg2: {arg_2}\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "ternary_results = exps.run_from_csv(\".dev/inputs/ibm_claim_stance_ternary_sample.csv\", ternary_ibm_few_shot_prompting, relation_dim=\"ternary\")\n",
    "\n",
    "ternary_results.f1_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
